{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook only for to learn implementation of KNN machine learing algorithm","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:05:24.709992Z","iopub.execute_input":"2021-06-11T11:05:24.710613Z","iopub.status.idle":"2021-06-11T11:05:24.720521Z","shell.execute_reply.started":"2021-06-11T11:05:24.710512Z","shell.execute_reply":"2021-06-11T11:05:24.719769Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Load iris dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\niris = load_iris()\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(iris['data'],iris['target'], random_state=304)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:05:24.726395Z","iopub.execute_input":"2021-06-11T11:05:24.726791Z","iopub.status.idle":"2021-06-11T11:05:25.772408Z","shell.execute_reply.started":"2021-06-11T11:05:24.726762Z","shell.execute_reply":"2021-06-11T11:05:25.771396Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Euclidean Distance","metadata":{}},{"cell_type":"markdown","source":"you can use Manhattan Distance or Mahalanobis Distance, here I used Euclidean Distance.[reference_here](https://towardsdatascience.com/importance-of-distance-metrics-in-machine-learning-modelling-e51395ffe60d)","metadata":{}},{"cell_type":"code","source":"def euc_distance(a, b):\n    lenth = len(a)\n    distance = 0\n    for i in range(lenth):\n        distance =distance + abs(a[i] - b[i])**2\n        \n    distance = distance**(1/2)\n    \n    return distance\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:05:25.774125Z","iopub.execute_input":"2021-06-11T11:05:25.774801Z","iopub.status.idle":"2021-06-11T11:05:25.780500Z","shell.execute_reply.started":"2021-06-11T11:05:25.774758Z","shell.execute_reply":"2021-06-11T11:05:25.779860Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Implemetation of KNN algorithm     ","metadata":{}},{"cell_type":"code","source":"def knn(X_train, X_test, y_train, k):\n    \n    \n    from collections import Counter\n    \n    \n    \n    y_hat_test = []\n    for test_data in X_test:\n        distances = []\n\n        for train_data in X_train:\n            distance = euc_distance(test_data, train_data)\n            distances.append(distance)\n        \n        \n        df_distance = pd.DataFrame(data=distances, columns=['dis'])\n        \n        \n        df_k = df_distance.sort_values(by=['dis'], axis=0)[:k]#select k number of nearest points\n\n        \n        counter = Counter(y_train[df_k.index])\n\n        \n        prediction = counter.most_common()[0][0]\n        \n        \n        y_hat_test.append(prediction)\n        \n    return y_hat_test\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:05:25.782051Z","iopub.execute_input":"2021-06-11T11:05:25.782528Z","iopub.status.idle":"2021-06-11T11:05:25.794141Z","shell.execute_reply.started":"2021-06-11T11:05:25.782500Z","shell.execute_reply":"2021-06-11T11:05:25.793125Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## accuracy for  iris dataset","metadata":{}},{"cell_type":"code","source":"y_hat_test = knn(X_train, X_test, y_train, 1)\nacc=sum(y_hat_test == y_test)/len(y_test) \n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:05:25.795530Z","iopub.execute_input":"2021-06-11T11:05:25.795875Z","iopub.status.idle":"2021-06-11T11:05:25.890886Z","shell.execute_reply.started":"2021-06-11T11:05:25.795839Z","shell.execute_reply":"2021-06-11T11:05:25.889935Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print('when K=1 accuracy is ', acc)\nprint('test error rate is  ', 1-acc)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:05:25.892234Z","iopub.execute_input":"2021-06-11T11:05:25.892634Z","iopub.status.idle":"2021-06-11T11:05:25.898334Z","shell.execute_reply.started":"2021-06-11T11:05:25.892593Z","shell.execute_reply":"2021-06-11T11:05:25.897005Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"when K=1 accuracy is  0.9473684210526315\ntest error rate is   0.052631578947368474\n","output_type":"stream"}]},{"cell_type":"code","source":"y_hat_test = knn(X_train, X_test, y_train, k=3)\nacc=sum(y_hat_test == y_test)/len(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:05:25.899800Z","iopub.execute_input":"2021-06-11T11:05:25.900346Z","iopub.status.idle":"2021-06-11T11:05:25.981371Z","shell.execute_reply.started":"2021-06-11T11:05:25.900301Z","shell.execute_reply":"2021-06-11T11:05:25.980534Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print('when K=3 accuracy is ', acc)\nprint('test error rate is  ', 1-acc)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:05:25.982632Z","iopub.execute_input":"2021-06-11T11:05:25.983043Z","iopub.status.idle":"2021-06-11T11:05:25.989052Z","shell.execute_reply.started":"2021-06-11T11:05:25.982975Z","shell.execute_reply":"2021-06-11T11:05:25.988121Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"when K=3 accuracy is  0.9473684210526315\ntest error rate is   0.052631578947368474\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}